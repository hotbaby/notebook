{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "maritime-calendar",
   "metadata": {},
   "source": [
    "# Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-reduction",
   "metadata": {},
   "source": [
    "## Kafka相关概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-sentence",
   "metadata": {},
   "source": [
    "Kakfa定位为一个分布式流式处理平台，高吞吐、可持久化、可水平扩展、支持流式数据处理。kafka可以被用作：\n",
    "\n",
    "* 消息系统，实现系统解耦、冗余存储、流量削峰，kafka还提供了大多数消息系统难以实现的**消息顺序性保障**和**消息回溯**功能\n",
    "* 存储系统，kafka把消息持久化到磁盘\n",
    "* 流式处理平台"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-champagne",
   "metadata": {},
   "source": [
    "### kafka技术架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-teaching",
   "metadata": {},
   "source": [
    "![](https://bj.bcebos.com/ipic/Kafka体系架构.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-machinery",
   "metadata": {},
   "source": [
    "* Producer生产者，发送消息的一方，负责把消息发送到kafka中\n",
    "* Consumer消费者，接收消息的一方，消费者连接到kafka上接收消息，并处理相应的业务逻辑\n",
    "* Broker服务代理节点，Broker可以看做一个Kakfa服务节点或者实例。\n",
    "* ZooKeeper，管理集群的元数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-stack",
   "metadata": {},
   "source": [
    "### 主题和分区"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-rainbow",
   "metadata": {},
   "source": [
    "主题是一个逻辑上的概念，它还可以细分多个分区，一个分区只属于单个主题。同一主题下的不同分区包含的消息式不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件时候都会分配一个特定的偏移量（offset）。offset是消息在分区中的唯一标识，**kafka通过offset保证分区内的顺序性，不过offset并不跨分区，kafka保证的式分区有序而不是主题有序**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-monroe",
   "metadata": {},
   "source": [
    "### 副本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-intro",
   "metadata": {},
   "source": [
    "kafka为分区引入了多副本（Replic）机制，通过增加副本数量可以提升容灾能力，副本之间式\"一主多从\"的关系，其中leader副本负责处理读写请求，follower副本只负责与leader副本的消息同步。副本处于不同的broker中，当leader副本发生故障时，从follower副本重新选举leader副本对外提供服务。Kafka通过多副本机制实现了故障的自动转移，当kafka某个broker失效时仍然能保证服务可用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-domain",
   "metadata": {},
   "source": [
    "分区中所有的副本统称为AR（Assigned Replicas），所有与leader副本保持一定程度同步的副本组成ISR（In-Sync Replicas），与leader副本滞后过多的副本组成OSR（Out-Of-Sync Replicas）。 `AR = ISR + OSR`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-campaign",
   "metadata": {},
   "source": [
    "leader副本故障时，只有ISR的副本才有资格被选举成leader副本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-horror",
   "metadata": {},
   "source": [
    "![kafka分区偏移量说明](https://bj.bcebos.com/ipic/Kafka分区中偏移量说明.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-cycling",
   "metadata": {},
   "source": [
    "ISR与HW和LEO有紧密的关系。HW是High Watermark的缩写，俗称高水位，它标识了一个特殊的偏移量（offset），消费者只能拉取这个offset之前的消息。LEO是Log End Offset的缩写，它标识当前日志文件中下一条待写入消息的偏移offset，LEFO的大小等于当前日志分区中最后一条消息的offset加1。分区ISR集合中的每个副本都会维护自己的LEO，ISR集合中最小LEO为分区的HW，对于消费者而言只能消费HW之前的消息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-brother",
   "metadata": {},
   "source": [
    "kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。同步复制要求所有的follower副本都复制完，这条消息才会被确认提交，这种方式极大的影响了性能。异步复制，follower副本异步地从leader副本中复制数据，数据只被leader副本写入就被认为已经成功提交。在这种情况下，如果follower副本复制都落后于leader副本，突然leader副本宕机，则会造成数据丢失。kafka使用这种ISR的方式有效地权衡了数据可靠性和性能之间的关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-length",
   "metadata": {},
   "source": [
    "## kafka事务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-malpractice",
   "metadata": {},
   "source": [
    "### 消息传输保障"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-district",
   "metadata": {},
   "source": [
    "消息传输保障有3个层级：\n",
    "\n",
    "* `at most once`: 至多一次，消息可能会丢失，但绝对不会重复传输\n",
    "* `at least once`: 最少一次，消息绝对不会丢失，但可能会重复传输\n",
    "* `exactly once`: 恰好一次，消息肯定会被传输，且只传输1次"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-return",
   "metadata": {},
   "source": [
    "kafka从`0.11.0.0`引入了幂等和事务两个特性，以此实现EOS(Exactly Once Sematics)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-willow",
   "metadata": {},
   "source": [
    "### 幂等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-control",
   "metadata": {},
   "source": [
    "幂等是对接口的多次调用和一次调用产生的结果是一致的。kafka生产者再进行重试的时候可能会重复写入消息，而使用kafka的幂等性功能后可以避免这种情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-discovery",
   "metadata": {},
   "source": [
    "为了实现生产者的幂等性，kafka引入了producer id（简称PID）和sequence number（序列号）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-beach",
   "metadata": {},
   "source": [
    "每个新的生产者实例在初始化的时候都会分配一个PID，这个PID对用户完全是不可见的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-uzbekistan",
   "metadata": {},
   "source": [
    "broker端会在内存中为每堆<PID, Partition>维护一个序列号SN_old，新消息的序列号SN_new\n",
    "\n",
    "* 新消息序列号SN_new比broker维护的序列号SN_old大于1，broker接收该消息\n",
    "* SN_new小于SN_old+1，说明消息重复写入，该消息被丢弃\n",
    "* SN_new大于SN_old+1，说明中间有消息未写入，出现了乱序，broker会抛出`OutOfOrderSequenceException`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-development",
   "metadata": {},
   "source": [
    "## FAQ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
