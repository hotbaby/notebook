{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "maritime-calendar",
   "metadata": {},
   "source": [
    "# Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-reduction",
   "metadata": {},
   "source": [
    "## Kafka相关概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-sentence",
   "metadata": {},
   "source": [
    "Kakfa定位为一个分布式流式处理平台，高吞吐、可持久化、可水平扩展、支持流式数据处理。kafka可以被用作：\n",
    "\n",
    "* 消息系统，实现系统解耦、冗余存储、流量削峰，kafka还提供了大多数消息系统难以实现的**消息顺序性保障**和**消息回溯**功能\n",
    "* 存储系统，kafka把消息持久化到磁盘\n",
    "* 流式处理平台"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-champagne",
   "metadata": {},
   "source": [
    "### kafka技术架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-teaching",
   "metadata": {},
   "source": [
    "![](https://bj.bcebos.com/ipic/Kafka体系架构.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-machinery",
   "metadata": {},
   "source": [
    "* Producer生产者，发送消息的一方，负责把消息发送到kafka中\n",
    "* Consumer消费者，接收消息的一方，消费者连接到kafka上接收消息，并处理相应的业务逻辑\n",
    "* Broker服务代理节点，Broker可以看做一个Kakfa服务节点或者实例。\n",
    "* ZooKeeper，管理集群的元数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-stack",
   "metadata": {},
   "source": [
    "### 主题和分区"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-rainbow",
   "metadata": {},
   "source": [
    "主题是一个逻辑上的概念，它还可以细分多个分区，一个分区只属于单个主题。同一主题下的不同分区包含的消息式不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件时候都会分配一个特定的偏移量（offset）。offset是消息在分区中的唯一标识，**kafka通过offset保证分区内的顺序性，不过offset并不跨分区，kafka保证的式分区有序而不是主题有序**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-monroe",
   "metadata": {},
   "source": [
    "### 副本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-horror",
   "metadata": {},
   "source": [
    "kafka为分区引入了多副本（Replic）机制，通过增加副本数量可以提升容灾能力，副本之间式\"一主多从\"的关系，其中leader副本负责处理读写请求，follower副本只负责与leader副本的消息同步。副本处于不同的broker中，当leader副本发生故障时，从follower副本重新选举leader副本对外提供服务。Kafka通过多副本机制实现了故障的自动转移，当kafka某个broker失效时仍然能保证服务可用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-domain",
   "metadata": {},
   "source": [
    "分区中所有的副本统称为AR（Assigned Replicas），所有与leader副本保持一定程度同步的副本组成ISR（In-Sync Replicas），与leader副本滞后过多的副本组成OSR（Out-Of-Sync Replicas）。 `AR = ISR + OSR`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-campaign",
   "metadata": {},
   "source": [
    "leader副本故障时，只有ISR的副本才有资格被选举成leader副本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-canvas",
   "metadata": {},
   "source": [
    "![kafka分区偏移量说明](https://bj.bcebos.com/ipic/Kafka分区中偏移量说明.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-queensland",
   "metadata": {},
   "source": [
    "ISR与HW和LEO有紧密的关系。HW是High Watermark的缩写，俗称高水位，它标识了一个特殊的偏移量（offset），消费者只能拉取这个offset之前的消息。LEO是Log End Offset的缩写，它标识当前日志文件中下一条待写入消息的偏移offset，LEFO的大小等于当前日志分区中最后一条消息的offset加1。分区ISR集合中的每个副本都会维护自己的LEO，ISR集合中最小LEO为分区的HW，对于消费者而言只能消费HW之前的消息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-syracuse",
   "metadata": {},
   "source": [
    "kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。同步复制要求所有的follower副本都复制完，这条消息才会被确认提交，这种方式极大的影响了性能。异步复制，follower副本异步地从leader副本中复制数据，数据只被leader副本写入就被认为已经成功提交。在这种情况下，如果follower副本复制都落后于leader副本，突然leader副本宕机，则会造成数据丢失。kafka使用这种ISR的方式有效地权衡了数据可靠性和性能之间的关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-microphone",
   "metadata": {},
   "source": [
    "## 生产者"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-uganda",
   "metadata": {},
   "source": [
    "### 重要的生产者参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-blackberry",
   "metadata": {},
   "source": [
    "* `acks`这个参数用来指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。\n",
    "    * `acks=1`，默认值为1，生产者发送消息之后，只要分区中的leader副本写入消息，那么就会收到服务端的成功响应\n",
    "    * `acks=0`，生产者发送消息之后，不需要等待任何服务端的响应\n",
    "    * `acks=-1`或者`acks=all`，生产者在发送消息成功后，需要等待ISR中的所有副本都成功写入消息后，才能收到服务端的响应"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-apartment",
   "metadata": {},
   "source": [
    "## 消费者"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-compound",
   "metadata": {},
   "source": [
    "### 消费者和消费者组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-liability",
   "metadata": {},
   "source": [
    "消费者（Consumer）负责订阅kafka中的主题（Topic），并且从订阅的主题上拉取消息。在kafka中，还有消费者组（Consumer Group）的概念，每个消费者都有一个对应的消费者组，当消费者发布到主题后，只会被投递到它的每个消费者组中的一个消费者。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-ranch",
   "metadata": {},
   "source": [
    "![](https://bj.bcebos.com/ipic/Kafka消费者与消费者组.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-queen",
   "metadata": {},
   "source": [
    "消费者组是一个逻辑上的概念，它将旗下的消费者归为一类，每个消费者只隶属于一个消费者组。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-dealing",
   "metadata": {},
   "source": [
    "### 客户端开发"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-appreciation",
   "metadata": {},
   "source": [
    "一个正常的消费逻辑包括以下几个步骤：\n",
    "\n",
    "1. 配置客户端参数，并创建消费者实例\n",
    "2. 订阅主题\n",
    "3. 拉取消息并消费\n",
    "4. 提交消费位移\n",
    "5. 关闭消费者实例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-cycle",
   "metadata": {},
   "source": [
    "### 位移提交"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-startup",
   "metadata": {},
   "source": [
    "消费者每次调用`poll()`方法时，它返回的是还没有消费过的消息。要做到这一点就必须记录上次消费的消费位移，并且这个消费位移要持久化保存，而不是保存在内存中，否则消费者重启之后就无法知道之前的消费位移。当有新的消费者加入时，必然会有再均衡的操作，对于一个分区而言，它可能在再均衡操作之后分配新的消费者，如果不持久化保存消费位移，那么新的消费者就无法知道之前的消费位移。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-fighter",
   "metadata": {},
   "source": [
    "#### 重复消费和消息丢失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-victorian",
   "metadata": {},
   "source": [
    "* 重复消费，消息被消费，位移未提交\n",
    "* 消息丢失，位移已提交，消息未消费"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-dairy",
   "metadata": {},
   "source": [
    "kafka默认的位移提交方式为自动提交，这个由消费者的客户端参数`enable.auto.commit`配置，默认为`true`。消费者每隔5秒会拉取分区中最大的消费位移进行提交，自动提交位移的动作是再`poll()`方法的逻辑里实现的。**在每次向服务器发起拉取请求之前，会检查是否有新的位移需要提交，如果可以，会提交上一次轮询的位移。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-blend",
   "metadata": {},
   "source": [
    "### 再均衡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-command",
   "metadata": {},
   "source": [
    "再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费者具备高可用和伸缩性提供了保障，是我们可以方便安全的删除消费者组内的消费者或者往消费者组内添加消费者。**再均衡期间，消费组内的消费者是无法读取消息的。也就是说，再均衡期间，消费者变得不可用。** 另外，当一个分区被重新分配给另一个消费者时，消费者的当前状态也会消失。比如消费者消费完某一个分区的一部分消息时还没有来得及提交消费位移就发生了再均衡操作，之后这个分区又分配给消费者组内另外一个消费者，原来被消费完的消息又被重新消费了一遍，也就是发生了**重复消费**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-length",
   "metadata": {},
   "source": [
    "## kafka事务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-malpractice",
   "metadata": {},
   "source": [
    "### 消息传输保障"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-district",
   "metadata": {},
   "source": [
    "消息传输保障有3个层级：\n",
    "\n",
    "* `at most once`: 至多一次，消息可能会丢失，但绝对不会重复传输\n",
    "* `at least once`: 最少一次，消息绝对不会丢失，但可能会重复传输\n",
    "* `exactly once`: 恰好一次，消息肯定会被传输，且只传输1次"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-return",
   "metadata": {},
   "source": [
    "kafka从`0.11.0.0`引入了幂等和事务两个特性，以此实现EOS(Exactly Once Sematics)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-willow",
   "metadata": {},
   "source": [
    "### 幂等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-control",
   "metadata": {},
   "source": [
    "幂等是对接口的多次调用和一次调用产生的结果是一致的。kafka生产者再进行重试的时候可能会重复写入消息，而使用kafka的幂等性功能后可以避免这种情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-discovery",
   "metadata": {},
   "source": [
    "为了实现生产者的幂等性，kafka引入了producer id（简称PID）和sequence number（序列号）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-beach",
   "metadata": {},
   "source": [
    "每个新的生产者实例在初始化的时候都会分配一个PID，这个PID对用户完全是不可见的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-uzbekistan",
   "metadata": {},
   "source": [
    "broker端会在内存中为每堆<PID, Partition>维护一个序列号SN_old，新消息的序列号SN_new\n",
    "\n",
    "* 新消息序列号SN_new比broker维护的序列号SN_old大于1，broker接收该消息\n",
    "* SN_new小于SN_old+1，说明消息重复写入，该消息被丢弃\n",
    "* SN_new大于SN_old+1，说明中间有消息未写入，出现了乱序，broker会抛出`OutOfOrderSequenceException`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-development",
   "metadata": {},
   "source": [
    "## FAQ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
